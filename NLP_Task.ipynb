{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Required libraries....\n"
      ],
      "metadata": {
        "id": "5mEbstmxO7bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "lhvJ64sQPE_N"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "KoZY-AVkXPPL",
        "outputId": "b05b47a8-9913-4dce-b5fc-06ca2f5fd254"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b749b3a6-cf78-4fa1-99be-75474ac7f050\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b749b3a6-cf78-4fa1-99be-75474ac7f050\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving NLP_Project.txt to NLP_Project.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and pre-process the data\n"
      ],
      "metadata": {
        "id": "JPjuY1IOXz7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"NLP_Project.txt\", \"r\", encoding=\"utf8\")\n",
        "#Store file in list\n",
        "lines =[]\n",
        "for i in file:\n",
        "    lines.append(i)\n",
        "\n",
        "#Convert list to string\n",
        "data = \"\"\n",
        "for i in lines:\n",
        "  data = ' '.join(lines)\n",
        "#replace unnecesasary stuff with space\n",
        "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('\"','').replace('\"', '').replace('**', '').replace('*', '' ) #\n",
        "\n",
        "#remove Unnecessary spaces\n",
        "data = data.split()\n",
        "data = ''.join(data)\n",
        "data[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "7k31JryCXtnq",
        "outputId": "e579128e-6fb7-4a8b-b53b-08c8ae26ca76"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'TheProjectGutenbergEBookofMetamorphosis,byFranzKafkaTranslatedbyDavidWyllie.ThiseBookisfortheuseofanyoneanywhereatnocostandwithalmostnorestrictionswhatsoever.Youmaycopyit,giveitawayorre-useitunderthetermsoftheProjectGutenbergLicenseincludedwiththiseBookoronlineatwww.gutenberg.orgThisisaCOPYRIGHTEDProjectGutenbergeBook,DetailsBelowPleasefollowthecopyrightguidelinesinthisfile.Title:MetamorphosisAuthor:FranzKafkaTranslator:DavidWyllieReleaseDate:August16,2005[EBook#5200]Firstposted:May13,2002Lastup'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Length of the data\n",
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU6FP4eHaQxG",
        "outputId": "0d5bc0c5-ae92-47cd-8e5c-8cb26a16e5bb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112543"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply Tokenization"
      ],
      "metadata": {
        "id": "j84aqiKNbIqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "# saving the tokenizer for predict function\n",
        "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
        "\n",
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "sequence_data[:15]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnP1T0HIa42q",
        "outputId": "2cfc2339-66ff-4a61-a251-ca6339feeebc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[105, 48, 49, 50, 51, 52, 15, 106, 107, 108, 109, 110, 111, 112, 113]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequence_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujguEA9lcGc6",
        "outputId": "2319ac0f-bb19-42df-8de9-d3e95a21dd6d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2930"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vHuhLASeLBU",
        "outputId": "0bf01374-b3df-4c28-b1bb-8fa7be1b2fb6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2608"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = []\n",
        "\n",
        "for i in range(3, len(sequence_data)):\n",
        "    words = sequence_data[i-3:i+1]\n",
        "    sequences.append(words)\n",
        "\n",
        "print(\" The Length of sequences are: \", len(sequences))\n",
        "sequences = np.array(sequences)\n",
        "sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cOg4PoOeeiu",
        "outputId": "1feded70-ee1c-4459-ee93-7ceaea8f39e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Length of sequences are:  2927\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[105,  48,  49,  50],\n",
              "       [ 48,  49,  50,  51],\n",
              "       [ 49,  50,  51,  52],\n",
              "       [ 50,  51,  52,  15],\n",
              "       [ 51,  52,  15, 106],\n",
              "       [ 52,  15, 106, 107],\n",
              "       [ 15, 106, 107, 108],\n",
              "       [106, 107, 108, 109],\n",
              "       [107, 108, 109, 110],\n",
              "       [108, 109, 110, 111]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in sequences:\n",
        "    X.append(i[0:3])\n",
        "    y.append(i[3])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "9EdzbrwWvth_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data: \", X[:10])\n",
        "print(\"Response: \", y[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWpJokRFwLhE",
        "outputId": "95f4caf0-212f-4b6e-acf0-52249fdd0059"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:  [[105  48  49]\n",
            " [ 48  49  50]\n",
            " [ 49  50  51]\n",
            " [ 50  51  52]\n",
            " [ 51  52  15]\n",
            " [ 52  15 106]\n",
            " [ 15 106 107]\n",
            " [106 107 108]\n",
            " [107 108 109]\n",
            " [108 109 110]]\n",
            "Response:  [ 50  51  52  15 106 107 108 109 110 111]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDL_aFmCwe5C",
        "outputId": "1639e454-2bc9-47f7-d574-dcda741db2a8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "# assume that your data is stored in two lists: X (input data) and y (output/target data)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "sLezKTrNyab8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, output_dim=10, input_length=3))\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation=\"relu\"))\n",
        "model.add(Dense(units=vocab_size, activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "aNnGj9pJwxFI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ6HcdeeyMMS",
        "outputId": "5b61613f-61ff-4763-bf6b-dd98a7b5f655"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 10)             26080     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2608)              2610608   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,685,688\n",
            "Trainable params: 15,685,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "keras.utils.plot_model(model, to_file='plot.png', show_layer_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "Cp5NI8wQpGQb",
        "outputId": "a4c21ce8-bd6b-4127-917c-513598290ed3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
        "model.fit(X, y, epochs=70, batch_size=64, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgYw3Jjdpcj-",
        "outputId": "efc91ff9-3ade-4190-d1cc-2e25dd38a0c4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2679\n",
            "Epoch 1: loss improved from inf to 0.26788, saving model to next_words.h5\n",
            "46/46 [==============================] - 8s 76ms/step - loss: 0.2679\n",
            "Epoch 2/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1221\n",
            "Epoch 2: loss improved from 0.26788 to 0.12206, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 32ms/step - loss: 0.1221\n",
            "Epoch 3/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1115\n",
            "Epoch 3: loss improved from 0.12206 to 0.11146, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 0.1115\n",
            "Epoch 4/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1379\n",
            "Epoch 4: loss did not improve from 0.11146\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.1379\n",
            "Epoch 5/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.2746\n",
            "Epoch 5: loss did not improve from 0.11146\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 0.2767\n",
            "Epoch 6/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.4180\n",
            "Epoch 6: loss did not improve from 0.11146\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.4216\n",
            "Epoch 7/70\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.3434\n",
            "Epoch 7: loss did not improve from 0.11146\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.3439\n",
            "Epoch 8/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2067\n",
            "Epoch 8: loss did not improve from 0.11146\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 0.2067\n",
            "Epoch 9/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1658\n",
            "Epoch 9: loss did not improve from 0.11146\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 0.1658\n",
            "Epoch 10/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.1297\n",
            "Epoch 10: loss did not improve from 0.11146\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1295\n",
            "Epoch 11/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.1096\n",
            "Epoch 11: loss improved from 0.11146 to 0.11142, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.1114\n",
            "Epoch 12/70\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.0769\n",
            "Epoch 12: loss improved from 0.11142 to 0.07767, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0777\n",
            "Epoch 13/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0635\n",
            "Epoch 13: loss improved from 0.07767 to 0.06329, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 25ms/step - loss: 0.0633\n",
            "Epoch 14/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0549\n",
            "Epoch 14: loss improved from 0.06329 to 0.05489, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 0.0549\n",
            "Epoch 15/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0509\n",
            "Epoch 15: loss improved from 0.05489 to 0.05032, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 25ms/step - loss: 0.0503\n",
            "Epoch 16/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0703\n",
            "Epoch 16: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0703\n",
            "Epoch 17/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0619\n",
            "Epoch 17: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0619\n",
            "Epoch 18/70\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.0662\n",
            "Epoch 18: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0664\n",
            "Epoch 19/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0953\n",
            "Epoch 19: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 0.0953\n",
            "Epoch 20/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.2124\n",
            "Epoch 20: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.2116\n",
            "Epoch 21/70\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.2844\n",
            "Epoch 21: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 0.2950\n",
            "Epoch 22/70\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.4512\n",
            "Epoch 22: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.4636\n",
            "Epoch 23/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.4270\n",
            "Epoch 23: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.4270\n",
            "Epoch 24/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.3146\n",
            "Epoch 24: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.3155\n",
            "Epoch 25/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.1970\n",
            "Epoch 25: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1963\n",
            "Epoch 26/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1076\n",
            "Epoch 26: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 0.1076\n",
            "Epoch 27/70\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.1059\n",
            "Epoch 27: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 0.1062\n",
            "Epoch 28/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0686\n",
            "Epoch 28: loss did not improve from 0.05032\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0679\n",
            "Epoch 29/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0316\n",
            "Epoch 29: loss improved from 0.05032 to 0.03121, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.0312\n",
            "Epoch 30/70\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.0251\n",
            "Epoch 30: loss improved from 0.03121 to 0.02451, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.0245\n",
            "Epoch 31/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0157\n",
            "Epoch 31: loss improved from 0.02451 to 0.01625, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0163\n",
            "Epoch 32/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0141\n",
            "Epoch 32: loss improved from 0.01625 to 0.01388, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.0139\n",
            "Epoch 33/70\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.0104\n",
            "Epoch 33: loss improved from 0.01388 to 0.01069, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 25ms/step - loss: 0.0107\n",
            "Epoch 34/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0087\n",
            "Epoch 34: loss improved from 0.01069 to 0.00867, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 0.0087\n",
            "Epoch 35/70\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.0081\n",
            "Epoch 35: loss improved from 0.00867 to 0.00839, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 0.0084\n",
            "Epoch 36/70\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.0057\n",
            "Epoch 36: loss improved from 0.00839 to 0.00623, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 0.0062\n",
            "Epoch 37/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0057\n",
            "Epoch 37: loss improved from 0.00623 to 0.00561, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 0.0056\n",
            "Epoch 38/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0062\n",
            "Epoch 38: loss did not improve from 0.00561\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.0062\n",
            "Epoch 39/70\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.0056\n",
            "Epoch 39: loss improved from 0.00561 to 0.00530, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.0053\n",
            "Epoch 40/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0059\n",
            "Epoch 40: loss did not improve from 0.00530\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.0058\n",
            "Epoch 41/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0059\n",
            "Epoch 41: loss did not improve from 0.00530\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0059\n",
            "Epoch 42/70\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.0067\n",
            "Epoch 42: loss did not improve from 0.00530\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0064\n",
            "Epoch 43/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0050\n",
            "Epoch 43: loss improved from 0.00530 to 0.00493, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0049\n",
            "Epoch 44/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0052\n",
            "Epoch 44: loss did not improve from 0.00493\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0051\n",
            "Epoch 45/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0049\n",
            "Epoch 45: loss improved from 0.00493 to 0.00490, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 0.0049\n",
            "Epoch 46/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0068\n",
            "Epoch 46: loss did not improve from 0.00490\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0067\n",
            "Epoch 47/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0046\n",
            "Epoch 47: loss improved from 0.00490 to 0.00464, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0046\n",
            "Epoch 48/70\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.0056\n",
            "Epoch 48: loss did not improve from 0.00464\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 0.0053\n",
            "Epoch 49/70\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.0049\n",
            "Epoch 49: loss did not improve from 0.00464\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 0.0047\n",
            "Epoch 50/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0053\n",
            "Epoch 50: loss did not improve from 0.00464\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 0.0052\n",
            "Epoch 51/70\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.0041\n",
            "Epoch 51: loss did not improve from 0.00464\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.0053\n",
            "Epoch 52/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0045\n",
            "Epoch 52: loss did not improve from 0.00464\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0050\n",
            "Epoch 53/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0054\n",
            "Epoch 53: loss did not improve from 0.00464\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0053\n",
            "Epoch 54/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0051\n",
            "Epoch 54: loss did not improve from 0.00464\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0050\n",
            "Epoch 55/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0047\n",
            "Epoch 55: loss improved from 0.00464 to 0.00462, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0046\n",
            "Epoch 56/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0048\n",
            "Epoch 56: loss did not improve from 0.00462\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.0048\n",
            "Epoch 57/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0048\n",
            "Epoch 57: loss did not improve from 0.00462\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0048\n",
            "Epoch 58/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0045\n",
            "Epoch 58: loss improved from 0.00462 to 0.00439, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0044\n",
            "Epoch 59/70\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.0049\n",
            "Epoch 59: loss did not improve from 0.00439\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.0047\n",
            "Epoch 60/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0048\n",
            "Epoch 60: loss did not improve from 0.00439\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0047\n",
            "Epoch 61/70\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.0047\n",
            "Epoch 61: loss did not improve from 0.00439\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0046\n",
            "Epoch 62/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0043\n",
            "Epoch 62: loss improved from 0.00439 to 0.00432, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.0043\n",
            "Epoch 63/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0050\n",
            "Epoch 63: loss did not improve from 0.00432\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0049\n",
            "Epoch 64/70\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.0060\n",
            "Epoch 64: loss did not improve from 0.00432\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.0058\n",
            "Epoch 65/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0041\n",
            "Epoch 65: loss improved from 0.00432 to 0.00407, saving model to next_words.h5\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 0.0041\n",
            "Epoch 66/70\n",
            "43/46 [===========================>..] - ETA: 0s - loss: 0.0036\n",
            "Epoch 66: loss did not improve from 0.00407\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 0.0045\n",
            "Epoch 67/70\n",
            "44/46 [===========================>..] - ETA: 0s - loss: 0.0048\n",
            "Epoch 67: loss did not improve from 0.00407\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 0.0050\n",
            "Epoch 68/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0048\n",
            "Epoch 68: loss did not improve from 0.00407\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0048\n",
            "Epoch 69/70\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.0047\n",
            "Epoch 69: loss did not improve from 0.00407\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0047\n",
            "Epoch 70/70\n",
            "45/46 [============================>.] - ETA: 0s - loss: 0.0047\n",
            "Epoch 70: loss did not improve from 0.00407\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 0.0046\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbf311df700>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "loss = model.evaluate(X, y, batch_size=64)\n",
        "print(f\"Test loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxx3pfE1txUf",
        "outputId": "802355fd-545d-412b-e628-aa094ba0283a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 8ms/step - loss: 0.0033\n",
            "Test loss: 0.003308079903945327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = load_model('next_words.h5')\n",
        "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = np.array(sequence)\n",
        "  preds = np.argmax(model.predict(sequence))\n",
        "  predicted_word = \"\"\n",
        "  \n",
        "  for key, value in tokenizer.word_index.items():\n",
        "      if value == preds:\n",
        "          predicted_word = key\n",
        "          break\n",
        "  \n",
        "  print(predicted_word)\n",
        "  return predicted_word"
      ],
      "metadata": {
        "id": "k7AMZYLz-Osz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "  text = input(\"Enter your line: \")\n",
        "  \n",
        "  if text == \"0\":\n",
        "      print(\"Execution completed.....\")\n",
        "      break\n",
        "  \n",
        "  else:\n",
        "      try:\n",
        "          text = text.split(\" \")\n",
        "          text = text[-3:]\n",
        "          print(text)\n",
        "        \n",
        "          Predict_Next_Words(model, tokenizer, text)\n",
        "          \n",
        "      except Exception as e:\n",
        "        print(\"Error occurred: \",e)\n",
        "        continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2HhJlu4-XDQ",
        "outputId": "f919f932-6ff0-48f9-c3c8-3022f8ac4d70"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your line: The Project Gutenberg\n",
            "['The', 'Project', 'Gutenberg']\n",
            "1/1 [==============================] - 1s 657ms/step\n",
            "1\n",
            "Enter your line: This eBook is\n",
            "['This', 'eBook', 'is']\n",
            "1/1 [==============================] - 1s 639ms/step\n",
            "gregor'ssisterwouldleaveherworktohelphermother\n",
            "Enter your line: 0\n",
            "Execution completed.....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z3OQFe5UpQuv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}